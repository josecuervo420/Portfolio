{
  "cells": [
    {
      "source": [
        "!pip install portalocker"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7W2XKxf8VzQ",
        "outputId": "1d2fcbc7-05cd-4949-de68-dbca26932c04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (2.8.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QCxjpgrFVWG"
      },
      "outputs": [],
      "source": [
        "from torchtext.datasets import IMDB\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from collections import defaultdict, Counter\n",
        "import random\n",
        "import portalocker"
      ]
    },
    {
      "source": [
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.datasets import IMDB\n",
        "from collections import Counter\n",
        "\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "def yield_tokens(data_iter, special_tokens):\n",
        "    for token in special_tokens:\n",
        "        yield [token]\n",
        "    for _, text in data_iter:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "special_tokens = [\"<unk>\", \"<pad>\", \"<start>\", \"<end>\"]\n",
        "\n",
        "train_iter = IMDB(split='train')\n",
        "\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_iter, special_tokens), specials=special_tokens)\n",
        "\n",
        "vocab.set_default_index(vocab[\"<unk>\"])\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "ty2xCHMlIFcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xcRLvvIUFVWJ"
      },
      "outputs": [],
      "source": [
        "def build_ngram_model(data, n=3):\n",
        "    model = defaultdict(Counter)\n",
        "    for sentence in data:\n",
        "        for i in range(len(sentence)-n+1):\n",
        "            context = tuple(sentence[i:i+n-1])\n",
        "            target = sentence[i+n-1]\n",
        "            model[context][target] += 1\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bnzmXrNFVWJ",
        "outputId": "b1c4d6b5-21a8-421d-da1d-e55a3fce1390"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lock acquired. Press Enter to release lock...\n",
            "/usr/bin/python3\n"
          ]
        }
      ],
      "source": [
        "import portalocker\n",
        "with open(\"test.lock\", \"w\") as lock_file:\n",
        "    portalocker.lock(lock_file, portalocker.LOCK_EX)\n",
        "    input(\"Lock acquired. Press Enter to release lock...\")\n",
        "\n",
        "import sys\n",
        "print(sys.executable)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CR5ywhkzFVWJ"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        output, (hidden, cell) = self.lstm(embedded)\n",
        "        output = self.fc(output[:, -1, :])\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uPVsnXZFVWJ"
      },
      "outputs": [],
      "source": [
        "from torchtext.datasets import IMDB\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from collections import Counter\n",
        "\n",
        "def load_data(data_type='train'):\n",
        "    tokenizer = get_tokenizer('basic_english')\n",
        "    counter = Counter()\n",
        "    for label, line in IMDB(split=data_type):\n",
        "        counter.update(tokenizer(line))\n",
        "    tokenized_text = [tok for tok, cnt in counter.items() for _ in range(cnt)]\n",
        "    return tokenized_text\n",
        "\n",
        "tokenized_text = load_data('train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uerowftJFVWK"
      },
      "outputs": [],
      "source": [
        "def build_ngram_model(tokenized_text, n=3):\n",
        "    model = {}\n",
        "    for i in range(len(tokenized_text)-n):\n",
        "        gram = tuple(tokenized_text[i:i+n-1])\n",
        "        next_word = tokenized_text[i+n-1]\n",
        "        if gram not in model:\n",
        "            model[gram] = {}\n",
        "        if next_word not in model[gram]:\n",
        "            model[gram][next_word] = 0\n",
        "        model[gram][next_word] += 1\n",
        "    for gram in model.keys():\n",
        "        total = float(sum(model[gram].values()))\n",
        "        for word in model[gram]:\n",
        "            model[gram][word] /= total\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSaMUwfzFVWK"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def generate_text(model, start_text, num_words=20, n=3):\n",
        "    result = start_text.split()\n",
        "    for _ in range(num_words):\n",
        "        state = tuple(result[-(n-1):])\n",
        "        next_words = model.get(state, None)\n",
        "        if not next_words:\n",
        "            break\n",
        "        next_word = random.choices(list(next_words.keys()), weights=next_words.values())[0]\n",
        "        result.append(next_word)\n",
        "    return ' '.join(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_nPjMgpFVWK",
        "outputId": "3c9434c1-9410-4bcf-e9e9-320d72c4ef4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My favorite movie\n",
            "My favorite movie\n",
            "My favorite movie\n",
            "My favorite movie\n",
            "My favorite movie\n"
          ]
        }
      ],
      "source": [
        "tokenized_text = load_data('train')\n",
        "ngram_model = build_ngram_model(tokenized_text, n=3)\n",
        "\n",
        "for _ in range(5):\n",
        "    print(generate_text(ngram_model, \"My favorite movie\", num_words=20, n=3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7omgFSEjFVWK"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "\n",
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, data_iter, vocab, tokenizer):\n",
        "        self.vocab = vocab\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = []\n",
        "        for label, text in data_iter:\n",
        "            numericalized_text = [self.vocab.get('<start>', self.vocab.get('<unk>'))] + \\\n",
        "                                 [self.vocab.get(token, self.vocab.get('<unk>')) for token in self.tokenizer(text)] + \\\n",
        "                                 [self.vocab.get('<end>', self.vocab.get('<unk>'))]\n",
        "            self.data.append((numericalized_text, label))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        numericalized_text, label = self.data[idx]\n",
        "        input_sequence = torch.tensor(numericalized_text[:-1], dtype=torch.long)\n",
        "        target_sequence = torch.tensor(numericalized_text[1:], dtype=torch.long)\n",
        "        return input_sequence, target_sequence, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AH_389fOFVWL"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 100\n",
        "hidden_dim = 256\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "model = LSTMModel(vocab_size, embedding_dim, hidden_dim)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0JZd8RuFVWL"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.datasets import IMDB\n",
        "from torchtext.vocab import Vocab\n",
        "\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "def yield_tokens(data_iter):\n",
        "    for _, text in data_iter:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "train_iter = IMDB(split='train')\n",
        "\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=['<unk>', '<pad>', '<start>', '<end>'])\n",
        "\n",
        "vocab.set_default_index(vocab['<unk>'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMVGJw5dFVWL"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmZo6A8bFVWL",
        "outputId": "d3b44e5d-268a-48c5-9a68-1e31007e803f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-2bc203643c50>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  input_sequences_padded = pad_sequence([torch.tensor(seq) for seq in input_sequences], batch_first=True, padding_value=0)\n",
            "<ipython-input-15-2bc203643c50>:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  targets_padded = pad_sequence([torch.tensor(tgt) for tgt in targets], batch_first=True, padding_value=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.997724272310734\n",
            "Epoch 2, Loss: 2.9617259427905083\n",
            "Epoch 3, Loss: 2.9171161204576492\n",
            "Epoch 4, Loss: 2.8302216082811356\n",
            "Epoch 5, Loss: 2.6873877570033073\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_classes):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        output, _ = self.lstm(embedded)\n",
        "        output = self.fc(output)\n",
        "        return output\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, input_sequences, targets):\n",
        "        self.input_sequences = input_sequences\n",
        "        self.targets = targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_sequences[idx], self.targets[idx]\n",
        "\n",
        "def collate_fn(batch):\n",
        "    input_sequences, targets = zip(*batch)\n",
        "    input_sequences_padded = pad_sequence([torch.tensor(seq) for seq in input_sequences], batch_first=True, padding_value=0)\n",
        "    targets_padded = pad_sequence([torch.tensor(tgt) for tgt in targets], batch_first=True, padding_value=0)\n",
        "    return input_sequences_padded, targets_padded\n",
        "\n",
        "vocab_size = 10000\n",
        "num_classes = 20\n",
        "\n",
        "input_sequences = torch.randint(0, vocab_size, (1000, 10))\n",
        "targets = torch.randint(0, num_classes, (1000, 10))\n",
        "\n",
        "dataset = TextDataset(input_sequences, targets)\n",
        "train_loader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "model = LSTMModel(vocab_size, embedding_dim=100, hidden_dim=256, num_classes=num_classes)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "loss_values = []\n",
        "\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for input_sequences, targets in train_loader:\n",
        "        input_sequences, targets = input_sequences.long(), targets.long()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(input_sequences)\n",
        "\n",
        "        loss = criterion(predictions.view(-1, num_classes), targets.view(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    average_loss = total_loss / len(train_loader)\n",
        "    loss_values.append(average_loss)\n",
        "    print(f'Epoch {epoch+1}, Loss: {average_loss}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "file_path = '/content/bul.txt'\n",
        "if os.path.exists(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        data = f.read()\n",
        "    print(\"Dataset loaded successfully.\")\n",
        "else:\n",
        "    print(\"File not found. Please check the file path.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Py6dYSNXNYKG",
        "outputId": "45b416b4-80e5-4f69-b895-b0d66c858efb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File not found. Please check the file path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim\n",
        "import gensim.downloader as api\n",
        "\n",
        "# Download the GloVe embeddings\n",
        "api.load('glove-wiki-gigaword-100')\n",
        "\n",
        "# Load the embeddings into a dictionary\n",
        "glove_embeddings = api.load('glove-wiki-gigaword-100')\n",
        "\n",
        "# Get the word vector for a given word\n",
        "word_vector = glove_embeddings.get_vector('word')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aH3TROkA96vo",
        "outputId": "1b257e4f-22cc-486d-974e-8b3c56c3af29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors"
      ],
      "metadata": {
        "id": "cxnSjUPzP3xM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJgSgmiy-vyR",
        "outputId": "dd8e1f20-2f6a-4faf-956d-7cdd060d4e2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-20 03:50:07--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2024-03-20 03:50:07--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2024-03-20 03:50:08--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.02MB/s    in 2m 39s  \n",
            "\n",
            "2024-03-20 03:52:47 (5.17 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "source": [
        "!unzip glove.6B.zip"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qrlEqiY-yQL",
        "outputId": "8da42081-93c2-4b92-c13a-2e3aca64c08e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ]
    },
    {
      "source": [
        "# Check if the file exists at the specified path\n",
        "!ls /content/glove.6B.100d.txt\n",
        "\n",
        "# If the file does not exist, download it\n",
        "if not os.path.exists('/content/glove.6B.100d.txt'):\n",
        "    !wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "    !unzip glove.6B.zip\n",
        "\n",
        "# Update the file path if necessary\n",
        "glove_path = '/content/glove.6B.100d.txt'\n",
        "\n",
        "# Load the embeddings\n",
        "glove_embeddings = load_glove_embeddings(glove_path)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMnZLElH_Det",
        "outputId": "78453a84-17e9-47bf-b0ab-52664c5cbb03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/glove.6B.100d.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glove_path = '/content/glove.6B.100d.txt'\n",
        "import numpy as np\n",
        "\n",
        "def load_glove_embeddings(path):\n",
        "    embeddings = {}\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            vector = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings[word] = vector\n",
        "    return embeddings\n",
        "\n",
        "glove_embeddings = load_glove_embeddings(glove_path)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "vocab = ['hello', 'world', '<unk>', '<pad>']\n",
        "vocab_size = len(vocab)\n",
        "embedding_dim = 100\n",
        "weights_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "for i, word in enumerate(vocab):\n",
        "    try:\n",
        "        weights_matrix[i] = glove_embeddings[word]\n",
        "    except KeyError:\n",
        "        weights_matrix[i] = np.random.normal(scale=0.6, size=(embedding_dim, ))\n",
        "\n",
        "embedding_layer = nn.Embedding(vocab_size, embedding_dim)\n",
        "embedding_layer.weight.data.copy_(torch.from_numpy(weights_matrix))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKU0VfK2ib5s",
        "outputId": "d9795d05-9f9f-495e-8786-19a3ad5bc8ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.6688e-01,  3.9632e-01,  6.1690e-01, -7.7451e-01, -1.0390e-01,\n",
              "          2.6697e-01,  2.7880e-01,  3.0992e-01,  5.4685e-03, -8.5256e-02,\n",
              "          7.3602e-01, -9.8432e-02,  5.4790e-01, -3.0305e-02,  3.3479e-01,\n",
              "          1.4094e-01, -7.0003e-03,  3.2569e-01,  2.2902e-01,  4.6557e-01,\n",
              "         -1.9531e-01,  3.7491e-01, -7.1390e-01, -5.1775e-01,  7.7039e-01,\n",
              "          1.0881e+00, -6.6011e-01, -1.6234e-01,  9.1190e-01,  2.1046e-01,\n",
              "          4.7494e-02,  1.0019e+00,  1.1133e+00,  7.0094e-01, -8.6960e-02,\n",
              "          4.7571e-01,  1.6360e-01, -4.4469e-01,  4.4690e-01, -9.3817e-01,\n",
              "          1.3101e-02,  8.5964e-02, -6.7456e-01,  4.9662e-01, -3.7827e-02,\n",
              "         -1.1038e-01, -2.8612e-01,  7.4606e-02, -3.1527e-01, -9.3774e-02,\n",
              "         -5.7069e-01,  6.6865e-01,  4.5307e-01, -3.4154e-01, -7.1660e-01,\n",
              "         -7.5273e-01,  7.5212e-02,  5.7903e-01, -1.1910e-01, -1.1379e-01,\n",
              "         -1.0026e-01,  7.1341e-01, -1.1574e+00, -7.4026e-01,  4.0452e-01,\n",
              "          1.8023e-01,  2.1449e-01,  3.7638e-01,  1.1239e-01, -5.3639e-01,\n",
              "         -2.5092e-02,  3.1886e-01, -2.5013e-01, -6.3283e-01, -1.1843e-02,\n",
              "          1.3770e+00,  8.6013e-01,  2.0476e-01, -3.6815e-01, -6.8874e-01,\n",
              "          5.3512e-01, -4.6556e-01,  2.7389e-01,  4.1180e-01, -8.5400e-01,\n",
              "         -4.6288e-02,  1.1304e-01, -2.7326e-01,  1.5636e-01, -2.0334e-01,\n",
              "          5.3586e-01,  5.9784e-01,  6.0469e-01,  1.3735e-01,  4.2232e-01,\n",
              "         -6.1279e-01, -3.8486e-01,  3.5842e-01, -4.8464e-01,  3.0728e-01],\n",
              "        [ 4.9177e-01,  1.1164e+00,  1.1424e+00,  1.4381e-01, -1.0696e-01,\n",
              "         -4.6727e-01, -4.4374e-01, -8.8024e-03, -5.0406e-01, -2.0549e-01,\n",
              "          5.0910e-01, -6.0904e-01,  2.0980e-01, -4.4836e-01, -7.0383e-01,\n",
              "          2.1516e-01,  6.6189e-01,  3.4620e-01, -8.9294e-01, -4.8032e-01,\n",
              "          4.3069e-01,  3.5697e-01,  8.4277e-01,  5.2344e-01,  8.2065e-01,\n",
              "          5.3183e-04,  2.4835e-01, -2.0887e-01,  8.1657e-01,  2.5048e-01,\n",
              "         -7.4761e-01, -1.1309e-02, -4.7481e-01,  6.4520e-02,  5.4517e-01,\n",
              "          2.0714e-01, -4.6237e-01,  1.0724e+00, -1.0526e+00, -1.5567e-01,\n",
              "         -7.9339e-01, -2.8366e-02,  1.0138e-01, -2.0909e-01,  4.5513e-01,\n",
              "          4.7330e-01,  6.8859e-01, -2.3840e-01, -5.5178e-02, -8.3022e-01,\n",
              "         -4.7127e-01,  2.2713e-01,  4.2651e-02,  1.1273e+00, -8.4776e-02,\n",
              "         -3.0378e+00, -1.8389e-01,  7.8244e-01,  1.6395e+00,  7.6146e-01,\n",
              "         -1.4258e-01,  6.5115e-01, -1.3549e-02, -5.1465e-01,  6.6951e-01,\n",
              "         -3.4464e-01, -1.4525e-01,  4.9258e-01,  8.0085e-01, -5.4971e-01,\n",
              "          3.9657e-01, -4.8571e-01, -4.3846e-01,  3.3180e-01,  1.0356e-01,\n",
              "         -2.8987e-02,  1.0896e-01, -4.5671e-01, -1.1150e+00, -8.2366e-02,\n",
              "          1.0186e+00,  3.0639e-02, -3.7162e-01,  1.0742e+00, -1.0642e+00,\n",
              "         -2.0298e-01, -9.8434e-01, -3.2040e-01,  1.5969e-01, -1.7910e-01,\n",
              "          2.1325e-01,  4.7155e-01,  6.8247e-01,  1.3784e-01, -1.0704e-01,\n",
              "         -1.8294e-01, -4.0082e-01, -5.0885e-01,  6.2556e-01,  4.3917e-01],\n",
              "        [-1.3476e-01,  3.6431e-01,  1.7762e+00,  4.0342e-01, -1.6546e-01,\n",
              "          5.4685e-01, -3.4107e-01, -5.3157e-01, -9.2859e-01, -1.3630e-01,\n",
              "         -5.4066e-02, -3.9193e-01,  5.2691e-01,  1.3026e-01, -6.8910e-03,\n",
              "         -1.3728e+00, -4.0548e-01,  2.6043e-02, -2.9479e-01,  6.0288e-01,\n",
              "          1.6202e-01,  3.5361e-01, -2.2797e-01, -3.0167e-01,  8.7017e-02,\n",
              "         -2.1071e-01,  3.1064e-01,  1.3919e-01,  1.1160e+00, -5.7537e-01,\n",
              "         -3.3739e-01, -3.4239e-01,  4.7572e-01, -1.0008e+00, -1.0392e-02,\n",
              "         -7.2643e-01, -9.9434e-01,  2.9595e-01, -3.7055e-01,  1.4884e-01,\n",
              "         -9.4714e-01,  1.1961e+00,  6.9659e-01, -2.8326e-01,  2.2775e-01,\n",
              "          2.5559e-02, -7.3575e-01,  4.1482e-01, -7.2564e-02,  3.2162e-01,\n",
              "          1.5798e-01, -2.9642e-01,  7.6237e-01,  6.2944e-01,  1.5591e-01,\n",
              "         -6.9042e-01, -8.2684e-01, -7.1210e-01,  2.0006e-01,  4.6590e-02,\n",
              "         -3.1214e-01,  1.6191e-01,  2.3075e-01, -4.1382e-01, -6.9674e-01,\n",
              "         -1.7053e-01, -3.0241e-01, -2.7194e-01, -9.4237e-01,  1.9698e-01,\n",
              "          7.1621e-02,  4.4249e-01, -6.6263e-01,  5.1986e-01,  5.8589e-01,\n",
              "          8.1054e-01, -5.5976e-01, -1.8797e+00, -7.0532e-01, -2.5856e-01,\n",
              "          1.2225e-01, -3.0228e-01,  1.1185e+00,  6.6575e-01, -9.0295e-02,\n",
              "         -8.7557e-01,  1.7205e-01, -3.2965e-02,  1.4252e+00,  7.8023e-01,\n",
              "         -1.2797e-01, -3.1046e-01, -1.0099e+00, -3.1761e-02, -2.7875e-01,\n",
              "         -3.8724e-01, -2.6597e-01, -1.0135e+00, -1.6668e-02,  8.5223e-01],\n",
              "        [-5.8330e-01, -2.7140e-01, -5.9155e-01,  6.3966e-01,  1.7634e-01,\n",
              "          3.5911e-01,  2.3357e-01, -7.3925e-01,  6.9862e-01,  4.4753e-01,\n",
              "         -8.8521e-01,  2.2817e-01,  8.3536e-02,  7.3667e-01, -2.1076e-01,\n",
              "         -3.9649e-01,  2.6402e-01, -1.0812e+00, -1.0927e-01,  4.4477e-01,\n",
              "         -9.7418e-03, -1.3458e-01, -4.9027e-02,  4.2371e-01, -5.7244e-01,\n",
              "          8.6001e-01, -3.6758e-01, -1.9738e-01, -3.4495e-01, -7.0881e-01,\n",
              "         -3.6521e-01,  2.9227e-01, -9.5665e-01,  1.0895e+00, -9.2007e-01,\n",
              "         -8.6883e-01, -5.7454e-01,  3.5406e-01, -2.9711e-01,  3.2798e-01,\n",
              "          5.7008e-01, -8.3956e-01,  1.5201e+00,  7.0601e-01, -4.6356e-02,\n",
              "          4.1493e-01, -3.5738e-01,  1.1575e-01, -1.0751e+00,  3.8002e-03,\n",
              "         -3.6256e-01,  8.3578e-02,  8.0586e-02,  1.8351e-01,  2.0086e-01,\n",
              "         -2.2056e-01,  1.8525e-01, -1.6711e+00,  3.2329e-01,  3.9321e-01,\n",
              "          2.6722e-01, -5.9948e-02,  1.1731e+00,  4.6423e-01, -6.8598e-01,\n",
              "          1.1815e-01, -1.6011e-01, -6.4787e-01,  1.0604e+00, -5.1632e-01,\n",
              "         -1.0053e+00, -1.4101e-02, -1.1304e-02,  8.7597e-01, -2.1326e-01,\n",
              "         -1.5208e+00, -5.7642e-01, -6.5106e-01, -1.4126e-01, -1.3129e-01,\n",
              "         -3.4969e-01,  2.7376e-01,  2.0739e-01,  1.3881e+00, -9.6455e-01,\n",
              "          7.6932e-01,  7.3284e-01, -2.8006e-01, -3.0686e-01,  2.1110e-01,\n",
              "         -1.6192e-01,  1.1951e+00, -2.1405e-01,  3.8794e-01,  3.9616e-01,\n",
              "          3.0344e-01,  6.5006e-01, -7.7280e-02, -4.1027e-01, -2.1777e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "mypytorchenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}